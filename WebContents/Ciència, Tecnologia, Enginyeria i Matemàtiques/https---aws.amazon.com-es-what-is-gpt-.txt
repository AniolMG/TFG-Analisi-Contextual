Saltar al contenido principal Haga clic aquí para volver a la página de inicio de Amazon Web Services Contacte con nosotros Soporte Español Mi cuenta Iniciar sesión Cree una cuenta AWS re:Invent Productos Soluciones Precios Documentación Aprender Red de socios AWS Marketplace Habilitación para clientes Eventos Explorar más ¿Qué es la informática en la nube? Centro de conceptos de computación en la nube Machine Learning e IA ¿Qué es GPT? Cree una cuenta de AWS Explore las ofertas de machine learning gratuitas Construya, despliegue y ejecute aplicaciones de machine learning en la nube de forma gratuita Consulte los servicios de machine learning Innove más rápido con el conjunto más completo de servicios de IA y ML Examinar los cursos de machine learning Empezar con la formación para desarrolladores de machine learning con contenido creado por expertos de AWS Leer los blogs de machine learning Lea sobre las últimas novedades de productos de machine learning de AWS y las prácticas recomendadas ¿Qué es GPT? ¿Por qué es importante GPT? ¿Cuáles son los casos de uso de GPT? ¿Cómo funciona GPT? ¿Cómo se entrenó GPT-3? ¿Cuáles son algunos ejemplos de aplicaciones que utilizan GPT? ¿Cómo puede ayudarle AWS a ejecutar modelos lingüísticos de gran tamaño como GPT-3? ¿Qué es GPT? Los transformadores generativos preentrenados, comúnmente conocidos como GPT, son una familia de modelos de redes neuronales que utilizan la arquitectura de transformadores y representan un avance clave en la inteligencia artificial (IA) que impulsa las aplicaciones de IA generativa, como ChatGPT. Los modelos GPT permiten a las aplicaciones crear texto y contenido (imágenes, música y más) de manera similar a como lo haría un ser humano y responder a preguntas de forma conversacional. Organizaciones de todos los sectores utilizan modelos GPT e IA generativa para bots de preguntas y respuestas, resumen de textos, generación de contenidos y búsqueda. ¿Por qué es importante GPT? Los modelos GPT y, en particular, la arquitectura de transformadores que emplean, representan un importante avance en la investigación de la IA. El auge de los modelos GPT es un punto de inflexión en la adopción generalizada del ML, ya que la tecnología ahora se puede utilizar para automatizar y mejorar un amplio conjunto de tareas, que van desde la traducción de idiomas y el resumen de documentos hasta la redacción de publicaciones de blog, la creación de sitios web, el diseño de imágenes, la creación de animaciones, la escritura de códigos, la investigación de temas complejos e incluso la composición de poemas. El valor de estos modelos reside en su velocidad y en la escala a la que pueden operar. Por ejemplo, si necesita varias horas para investigar, escribir y editar un artículo sobre física nuclear, un modelo GPT puede producir uno en cuestión de segundos. Los modelos GPT han impulsado la investigación en IA para lograr la inteligencia artificial general, lo que significa que las máquinas pueden ayudar a las organizaciones a alcanzar nuevos niveles de productividad y a reinventar sus aplicaciones y experiencias de cliente. ¿Cuáles son los casos de uso de GPT? Los modelos GPT son modelos de lenguaje de uso general que pueden completar una amplia gama de tareas, desde crear contenido original hasta escribir código, resumir textos y extraer datos de documentos. Estas son algunas maneras en las que puede utilizar los modelos GPT: Crear contenido para las redes sociales Los especialistas en marketing digital, con la ayuda de la inteligencia artificial (IA), pueden crear contenido para sus campañas en las redes sociales. Por ejemplo, los especialistas en marketing pueden solicitar a un modelo GPT que redacte el guion de un vídeo explicativo. El software de procesamiento de imágenes con tecnología GPT puede crear memes, vídeos, textos de marketing y otro contenido a partir de unas instrucciones escritas. Editar textos en estilos diferentes Los modelos GPT generan textos en estilos informales, humorísticos, profesionales y más. También permiten a los especialistas reescribir un texto en particular de una forma diferente. Por ejemplo, los abogados pueden usar un modelo GPT para convertir copias legales en simples notas explicativas. Escribir y aprender código Como modelos de lenguaje, los modelos GPT pueden entender y escribir código informático en diferentes lenguajes de programación. Dichos modelos pueden ayudar a los alumnos al explicarles los programas de ordenador en un lenguaje cotidiano. Además, los desarrolladores experimentados pueden usar las herramientas GPT para autosugerir fragmentos de código relevantes. Analizar datos El modelo GPT puede ayudar a los analistas de negocios a compilar grandes volúmenes de datos de manera eficiente. Los modelos de lenguaje buscan los datos requeridos y calculan y muestran los resultados en una tabla de datos o una hoja de cálculo. Algunas aplicaciones pueden representar los resultados en un gráfico o crear informes completos. Producir materiales de aprendizaje Los docentes pueden usar software basado en GPT para generar materiales de aprendizaje, como cuestionarios y tutoriales. Del mismo modo, pueden usar modelos GPT para evaluar las respuestas. Crear asistentes de voz interactivos Los modelos GPT permiten crear asistentes de voz interactivos inteligentes. Si bien muchos chatbots solo responden a indicaciones verbales básicas, los modelos GPT pueden producir chatbots con capacidades de IA conversacional. Además, estos chatbots pueden comunicarse oralmente como los humanos cuando se combinan con otras tecnologías de IA. ¿Cómo funciona GPT? Aunque es acertado describir los modelos GPT como inteligencia artificial (IA), se trata de una descripción generalizada. Más concretamente, los modelos GPT son modelos de predicción lingüística basados en redes neuronales y construidos sobre la arquitectura Transformer. Analizan las consultas en lenguaje natural, conocidas como prompts, y predicen la mejor respuesta posible basándose en su comprensión del lenguaje. Para ello, los modelos GPT se basan en los conocimientos que adquieren tras ser entrenados con cientos de miles de millones de parámetros en conjuntos de datos lingüísticos masivos. Pueden tener en cuenta el contexto de entrada y atender dinámicamente a distintas partes de la entrada, lo que les hace capaces de generar respuestas largas, no solo la siguiente palabra de una secuencia. Por ejemplo, cuando se le pide que genere un contenido inspirado en Shakespeare, un modelo GPT lo hace recordando y reconstruyendo nuevas frases y oraciones enteras con un estilo literario similar. Existen distintos tipos de redes neuronales, como las recurrentes y las convolucionales. Los modelos GPT son redes neuronales transformadoras. La arquitectura de la red neuronal transformadora utiliza mecanismos de atención propia para centrarse en distintas partes del texto de entrada con cada fase del procesamiento. Un modelo transformador obtiene más contexto y mejora el rendimiento en tareas de procesamiento de lenguaje natural (NLP). Tiene dos módulos principales, que explicamos a continuación. Más información sobre las redes neuronales » Más información sobre el procesamiento de lenguaje natural (NLP) » Codificador Los transformadores procesan las entradas de texto previamente como incrustaciones, que son representaciones matemáticas de una palabra. Cuando se codifican en un espacio vectorial, se espera que las palabras que están más juntas tengan un significado más cercano. Estas incrustaciones se procesan a través de un componente codificador que captura la información contextual de una secuencia de entrada. Cuando recibe una entrada, el bloque codificador de la red transformadora separa las palabras en incrustaciones y asigna un peso a cada una de ellas. Los pesos son parámetros que indican la relevancia de las palabras de una oración. Además, los codificadores de posición permiten que los modelos GPT eviten significados ambiguos cuando se usa una palabra en otras partes de una oración. Por ejemplo, la codificación de posición permite que el modelo transformador distinga las diferencias semánticas entre estas oraciones: Un perro persigue a un gato Un gato persigue a un perro Así pues, el codificador procesa la oración de entrada y genera una representación vectorial de longitud fija, conocida como incrustación. El módulo decodificado utiliza esta representación. Decodificador El decodificador usa la representación vectorial para predecir la salida solicitada. Tiene mecanismos de autoatención integrados para centrarse en diferentes partes de la entrada y adivinar la salida correspondiente. Las técnicas matemáticas complejas ayudan al decodificador a estimar varias salidas diferentes y a predecir la más precisa. En comparación con sus predecesores, como las redes neuronales recurrentes, los transformadores son más paralelizables porque no procesan las palabras secuencialmente de una en una, sino que procesan toda la entrada de una vez durante el ciclo de aprendizaje. Gracias a esto y a las miles de horas que los ingenieros dedicaron a ajustar y entrenar los modelos GPT, estos últimos pueden responder con fluidez a casi cualquier información que usted proporcione. ¿Cómo se entrenó GPT-3? En un artículo de investigación publicado, los investigadores describieron el preentrenamiento generativo como la capacidad de entrenar modelos lingüísticos con datos no etiquetados y lograr una predicción precisa. El primer modelo GPT, el GPT-1, se desarrolló en 2018. El GPT-4 se introdujo en marzo de 2023 como sucesor del GPT-3. El GPT-3 se entrenó con más de 175 mil millones de parámetros o pesos. Los ingenieros lo entrenaron con más de 45 terabytes de datos de fuentes como textos web, Common Crawl, libros y Wikipedia. Antes del entrenamiento, la calidad promedio de los conjuntos de datos mejoró a medida que el modelo maduraba de la versión 1 a la versión 3. El GPT-3 se entrenó en modo semisupervisado. En primer lugar, los ingenieros de machine learning alimentaron el modelo de aprendizaje profundo con los datos del entrenamiento sin etiquetar. El GPT-3 entendía las oraciones, las dividía y las reconstruía para formar unidades nuevas. En un entrenamiento sin supervisión, el GPT-3 intentó producir resultados precisos y realistas por sí mismo. Luego, los ingenieros de machine learning afinaron los resultados del entrenamiento supervisado, un proceso conocido como aprendizaje por refuerzo con retroalimentación humana (RLHF). Puede emplear los modelos GPT sin necesidad de entrenamiento adicional, o puede personalizarlos con algunos ejemplos para una tarea en concreto. ¿Cuáles son algunos ejemplos de aplicaciones que utilizan GPT? Desde su lanzamiento, los modelos GPT han llevado la inteligencia artificial (IA) a numerosas aplicaciones en diversas industrias. A continuación, se indican varios ejemplos: Los modelos GPT se pueden emplear para analizar los comentarios de los clientes y resumirlos en un texto fácilmente comprensible. Primero, puede recopilar datos sobre las opiniones de los clientes a partir de fuentes como encuestas, reseñas y chats en vivo, y luego puede pedirle a un modelo GPT que resuma los datos. Los modelos GPT se pueden utilizar para permitir que los personajes virtuales conversen de forma natural con jugadores humanos en la realidad virtual. Los modelos GPT se pueden utilizar para proporcionar un mejor servicio de búsqueda para el personal del departamento de soporte técnico. Pueden consultar la base de conocimientos del producto con un lenguaje conversacional para recuperar la información relevante del producto. ¿Cómo puede ayudarle AWS a ejecutar modelos lingüísticos de gran tamaño como GPT-3? Amazon Bedrock es la manera más sencilla de crear y escalar aplicaciones de IA generativa con modelos lingüísticos de gran tamaño, también conocidos como modelos fundacionales (FM), similares a GPT-3. Amazon Bedrock le proporciona acceso a través de una API a los modelos de base de las principales empresas emergentes de IA, incluidas AI21 Labs, Anthropic y Stability AI, junto con la familia de modelos más reciente de Amazon, Amazon Titan FM. Con la experiencia sin servidor de Bedrock, puede comenzar rápidamente, personalizar de forma privada los FM con sus propios datos e integrarlos e implementarlos fácilmente en sus aplicaciones mediante las herramientas y capacidades de AWS con las que está familiarizado (incluidas las integraciones con características de Amazon SageMaker ML como Experiments) para probar diferentes modelos y canalizaciones para administrar sus FM a escala sin tener que administrar ninguna infraestructura. Más información sobre la construcción con modelos de cimentación en Amazon Bedrock. Siguientes pasos del machine learning INTRODUCCIÓN A AWS Descubra cómo comenzar a utilizar AWS en cuestión de minutos CAPA GRATUITA DE AWS Adquiera experiencia práctica de manera gratuita con AWS durante 12 meses AWS TRAINING GRATIS Acceda a más de 500 cursos digitales gratuitos orientados a diferentes roles, niveles de habilidad y dominios para desarrollar sus habilidades en la nube de AWS Información sobre AWS ¿Qué es AWS? ¿Qué es la informática en la nube? Inclusión, diversidad e igualdad en AWS ¿Qué es DevOps? ¿Qué es un contenedor? ¿Qué es un lago de datos? Seguridad en la nube de AWS Novedades Blogs Notas de prensa